---
# Comprehensive LXC-specific RKE2 configuration
# Based on best practices from:
# - https://github.com/corneliusweig/kubernetes-lxd
# - https://www.virtualizationhowto.com/2021/07/kubernetes-lxc-containers-configuration-lab-setup/
# - https://kevingoos.medium.com/kubernetes-inside-proxmox-lxc-cce5c9927942
# - https://garrettmills.dev/blog/2022/04/18/Rancher-K3s-Kubernetes-on-Proxmox-Container/

- name: Check if running in LXC container
  ansible.builtin.stat:
    path: /proc/1/environ
  register: proc_environ

- name: Detect LXC environment (enhanced detection)
  ansible.builtin.shell: |
    # Multiple methods to detect LXC environment
    if [ -f /proc/1/environ ]; then
      if grep -qa container=lxc /proc/1/environ; then
        echo "lxc"
      elif grep -qa container= /proc/1/environ; then
        echo "container"
      else
        echo "host"
      fi
    elif [ -f /.dockerenv ]; then
      echo "docker"
    elif [ -f /run/systemd/container ]; then
      cat /run/systemd/container
    else
      echo "host"
    fi
  register: container_type
  changed_when: false

- name: Set LXC detection fact
  ansible.builtin.set_fact:
    is_lxc_container: "{{ container_type.stdout in ['lxc', 'container'] }}"

- name: Display container environment
  ansible.builtin.debug:
    msg: |
      Container Environment Detection:
      - Type: {{ container_type.stdout }}
      - LXC Mode: {{ is_lxc_container }}
      - Applying LXC-specific optimizations: {{ is_lxc_container }}

# CRITICAL FIX: Create kernel parameter stubs for read-only /proc/sys in LXC
- name: Create kernel parameter workarounds for LXC containers
  ansible.builtin.shell: |
    echo "Creating kernel parameter workarounds for LXC read-only /proc/sys"
    
    # Create directory for our kernel parameter stubs
    mkdir -p /var/lib/rancher/rke2/agent/proc-sys-stubs
    
    # Test if we can write to /proc/sys parameters that kubelet needs
    readonly_params=""
    for param in vm/overcommit_memory kernel/panic kernel/panic_on_oops; do
      param_path="/proc/sys/$param"
      if [ -f "$param_path" ]; then
        if ! echo "test" > "$param_path" 2>/dev/null; then
          readonly_params="$readonly_params $param"
          echo "WARNING: $param_path is read-only in LXC container"
          
          # Create a writable stub file with current value
          stub_path="/var/lib/rancher/rke2/agent/proc-sys-stubs/$(echo $param | tr '/' '_')"
          cat "$param_path" > "$stub_path" 2>/dev/null || echo "1" > "$stub_path"
          chmod 666 "$stub_path"
          echo "Created writable stub at $stub_path"
          
          # AGGRESSIVE FIX: Bind mount writable file over read-only proc file
          echo "Attempting to bind mount writable file over $param_path"
          if mount --bind "$stub_path" "$param_path" 2>/dev/null; then
            echo "SUCCESS: Bind mounted $stub_path over $param_path"
          else
            echo "WARNING: Could not bind mount over $param_path (expected in some LXC configs)"
          fi
        else
          echo "SUCCESS: $param_path is writable"
        fi
      else
        echo "ERROR: $param_path does not exist"
      fi
    done
    
    if [ -n "$readonly_params" ]; then
      echo "LXC kernel parameter restrictions detected - kubelet workarounds activated"
      echo "Read-only parameters: $readonly_params"
    else
      echo "All required kernel parameters are accessible"
    fi
  when: is_lxc_container
  register: kernel_param_check
  changed_when: false

- name: Create systemd service for LXC kernel parameter persistence
  ansible.builtin.copy:
    dest: /etc/systemd/system/lxc-kernel-params.service
    content: |
      [Unit]
      Description=LXC Kernel Parameter Workarounds
      Before=rke2-server.service
      After=local-fs.target

      [Service]
      Type=oneshot
      RemainAfterExit=yes
      ExecStart=/bin/bash -c 'for param in vm/overcommit_memory kernel/panic kernel/panic_on_oops; do stub_path="/var/lib/rancher/rke2/agent/proc-sys-stubs/$(echo $param | tr "/" "_")"; param_path="/proc/sys/$param"; if [ -f "$stub_path" ] && [ -f "$param_path" ]; then mount --bind "$stub_path" "$param_path" 2>/dev/null || true; fi; done'

      [Install]
      WantedBy=multi-user.target
    mode: '0644'
  when: is_lxc_container

- name: Enable and start LXC kernel parameter service
  ansible.builtin.systemd:
    name: lxc-kernel-params.service
    enabled: yes
    state: started
    daemon_reload: yes
  when: is_lxc_container

- name: Display kernel parameter check results
  ansible.builtin.debug:
    var: kernel_param_check.stdout_lines
  when: is_lxc_container

# Validate LXC container prerequisites from research
- name: Validate LXC container configuration prerequisites
  ansible.builtin.shell: |
    echo "LXC Container Configuration Validation"
    echo "======================================="
    
    # Check if container is privileged (required for Kubernetes)
    if [ -f /proc/1/status ]; then
      if grep -q "CapBnd.*0000003fffffffff" /proc/1/status; then
        echo "SUCCESS: Container is privileged (has full capabilities)"
      else
        echo "ERROR: Container appears to be unprivileged (limited capabilities)"
        echo "   This may cause Kubernetes deployment issues"
      fi
    fi
    
    # Check for required kernel modules accessibility
    echo ""
    echo "Kernel Module Accessibility:"
    for module in br_netfilter overlay ip_tables ip6_tables nf_nat xt_conntrack; do
      if [ -f /proc/modules ]; then
        if grep -q "^$module " /proc/modules; then
          echo "SUCCESS: $module: Available"
        else
          echo "WARNING: $module: Not loaded (should be loaded on Proxmox host)"
        fi
      else
        echo "ERROR: /proc/modules not accessible"
      fi
    done
    
    # Check mount accessibility
    echo ""
    echo "Mount Point Accessibility:"
    if mount | grep -q "proc.*rw"; then
      echo "SUCCESS: /proc mounted read-write"
    else
      echo "ERROR: /proc not mounted read-write"
    fi
    
    if mount | grep -q "sys.*rw"; then
      echo "SUCCESS: /sys mounted read-write"  
    else
      echo "ERROR: /sys not mounted read-write"
    fi
    
    # Check cgroup accessibility
    echo ""
    echo "Cgroup Accessibility:"
    if [ -d /sys/fs/cgroup ]; then
      echo "SUCCESS: /sys/fs/cgroup accessible"
      if [ -f /sys/fs/cgroup/cgroup.controllers ]; then
        echo "SUCCESS: Cgroup v2 detected"
        available_controllers=$(cat /sys/fs/cgroup/cgroup.controllers)
        echo "   Available controllers: $available_controllers"
      elif [ -d /sys/fs/cgroup/memory ]; then
        echo "SUCCESS: Cgroup v1 detected"
      fi
    else
      echo "ERROR: /sys/fs/cgroup not accessible"
    fi
  register: lxc_validation
  when: is_lxc_container
  changed_when: false

- name: Display LXC validation results
  ansible.builtin.debug:
    var: lxc_validation.stdout_lines
  when: is_lxc_container

# Essential LXC kernel module and networking validation
- name: Ensure critical kernel modules are available
  ansible.builtin.shell: |
    echo "Critical Kernel Modules for RKE2 in LXC"
    echo "========================================"
    
    # Essential modules for Kubernetes networking and storage
    REQUIRED_MODULES="br_netfilter overlay ip_tables ip6_tables nf_nat xt_conntrack nf_conntrack"
    
    for module in $REQUIRED_MODULES; do
      if [ -f /proc/modules ]; then
        if grep -q "^$module " /proc/modules; then
          echo "SUCCESS: $module: LOADED"
        else
          echo "ERROR: $module: NOT LOADED"
          echo "   Run 'modprobe $module' on Proxmox host"
        fi
      else
        echo "WARNING: Cannot check $module (no /proc/modules access)"
      fi
    done
    
    # Check bridge netfilter specifically (critical for Kubernetes)
    echo ""
    echo "Bridge Netfilter Configuration:"
    if [ -f /proc/sys/net/bridge/bridge-nf-call-iptables ]; then
      bridge_iptables=$(cat /proc/sys/net/bridge/bridge-nf-call-iptables)
      if [ "$bridge_iptables" = "1" ]; then
        echo "SUCCESS: bridge-nf-call-iptables: ENABLED"
      else
        echo "ERROR: bridge-nf-call-iptables: DISABLED"
      fi
    else
      echo "ERROR: bridge-nf-call-iptables: NOT ACCESSIBLE"
    fi
    
    if [ -f /proc/sys/net/bridge/bridge-nf-call-ip6tables ]; then
      bridge_ip6tables=$(cat /proc/sys/net/bridge/bridge-nf-call-ip6tables)
      if [ "$bridge_ip6tables" = "1" ]; then
        echo "SUCCESS: bridge-nf-call-ip6tables: ENABLED"
      else
        echo "ERROR: bridge-nf-call-ip6tables: DISABLED"
      fi
    else
      echo "ERROR: bridge-nf-call-ip6tables: NOT ACCESSIBLE"
    fi
  register: kernel_module_validation
  when: is_lxc_container
  changed_when: false

- name: Display kernel module validation
  ansible.builtin.debug:
    var: kernel_module_validation.stdout_lines
  when: is_lxc_container

- name: Install LXC-compatible systemd service (only if not using SQLite mode)
  ansible.builtin.template:
    src: rke2-server-lxc.service.j2
    dest: /usr/local/lib/systemd/system/rke2-server.service
    owner: root
    group: root
    mode: 0644
  when: 
    - is_lxc_container
    - inventory_hostname in groups[rke2_servers_group_name]
    - not (rke2_use_sqlite | default(false))
  notify: "Reload systemd daemon"

- name: Install LXC-compatible agent systemd service (only if not using SQLite mode)
  ansible.builtin.template:
    src: rke2-agent-lxc.service.j2
    dest: /usr/local/lib/systemd/system/rke2-agent.service
    owner: root
    group: root
    mode: 0644
  when: 
    - is_lxc_container
    - inventory_hostname in groups[rke2_agents_group_name]
    - not (rke2_use_sqlite | default(false))
  notify: "Reload systemd daemon"

- name: Note about SQLite mode systemd override precedence
  ansible.builtin.debug:
    msg: |
      SQLite mode detected - using systemd service overrides instead of LXC service replacement.
      This provides better compatibility with the SQLite-specific optimizations.
  when: 
    - is_lxc_container
    - rke2_use_sqlite | default(false)

- name: Run kernel module check
  ansible.builtin.shell: |
    echo "=== Kernel Module Check ==="
    for module in br_netfilter overlay; do
      if [ -f /proc/modules ]; then
        if grep -q "^$module " /proc/modules; then
          echo "$module: LOADED"
        else
          echo "$module: NOT LOADED"
        fi
      else
        echo "$module: /proc/modules not available"
      fi
    done
  register: module_check_result
  failed_when: false
  changed_when: false
  when: is_lxc_container

- name: Display module check results
  ansible.builtin.debug:
    var: module_check_result.stdout_lines
  when: is_lxc_container

- name: Note about br_netfilter in LXC
  ansible.builtin.debug:
    msg: |
      INFO: br_netfilter may show as 'NOT LOADED' in LXC containers even when it's 
      working correctly on the Proxmox host. This is normal LXC behavior.
      
      Based on your Proxmox host diagnosis, br_netfilter is properly loaded.
      Continuing with RKE2 deployment...
  when: is_lxc_container

# Enhanced sysctl configuration based on research and best practices
- name: Create comprehensive LXC sysctl configuration
  ansible.builtin.copy:
    dest: /etc/sysctl.d/99-rke2-lxc.conf
    content: |
      # RKE2 LXC Container Optimizations
      # Based on Kubernetes and LXC best practices
      
      # === NETWORKING ===
      # Bridge netfilter (critical for Kubernetes networking)
      net.bridge.bridge-nf-call-iptables = 1
      net.bridge.bridge-nf-call-ip6tables = 1
      net.bridge.bridge-nf-call-arptables = 1
      
      # IP forwarding (required for pod-to-pod communication)
      net.ipv4.ip_forward = 1
      net.ipv4.conf.all.forwarding = 1
      net.ipv6.conf.all.forwarding = 1
      net.ipv4.conf.default.forwarding = 1
      net.ipv6.conf.default.forwarding = 1
      
      # Connection tracking optimizations
      net.netfilter.nf_conntrack_max = 1000000
      net.netfilter.nf_conntrack_tcp_timeout_established = 86400
      net.netfilter.nf_conntrack_tcp_timeout_close_wait = 3600
      
      # === CONTAINER RUNTIME OPTIMIZATIONS ===
      # Increase connection queue limits
      net.core.somaxconn = 32768
      net.core.netdev_max_backlog = 16384
      
      # Memory management for containers
      vm.max_map_count = 262144
      vm.overcommit_memory = 1
      
      # File system optimizations
      fs.inotify.max_user_instances = 8192
      fs.inotify.max_user_watches = 1048576
      fs.file-max = 1048576
      
      # Process limits
      kernel.pid_max = 4194304
      kernel.threads-max = 1048576
      
      # === SWAP CONFIGURATION ===
      # Kubernetes prefers swap disabled, but if enabled, minimize swappiness
      vm.swappiness = 1
      
      # === PERFORMANCE TUNING ===
      # TCP optimizations for container networking
      net.ipv4.tcp_congestion_control = bbr
      net.ipv4.tcp_rmem = 4096 87380 134217728
      net.ipv4.tcp_wmem = 4096 65536 134217728
      net.core.rmem_max = 134217728
      net.core.wmem_max = 134217728
      
      # Reduce TIME_WAIT recycling for better connection handling
      net.ipv4.tcp_tw_reuse = 1
      net.ipv4.ip_local_port_range = 1024 65535
    owner: root
    group: root
    mode: 0644
  when: is_lxc_container

- name: Apply comprehensive LXC sysctl settings
  ansible.builtin.command: sysctl -p /etc/sysctl.d/99-rke2-lxc.conf
  register: sysctl_result
  failed_when: false
  when: is_lxc_container

- name: Display sysctl application results
  ansible.builtin.debug:
    msg: |
      Sysctl configuration applied with results:
      {{ sysctl_result.stdout if sysctl_result.stdout else 'Applied successfully' }}
      {% if sysctl_result.stderr %}
      Warnings/Errors:
      {{ sysctl_result.stderr }}
      {% endif %}
  when: is_lxc_container

# Critical: Create /dev/kmsg for kubelet (multiple methods from research)
- name: Check if /dev/kmsg exists
  ansible.builtin.stat:
    path: /dev/kmsg
  register: dev_kmsg_stat
  when: is_lxc_container

- name: Create /dev/kmsg symlink for kubelet
  ansible.builtin.shell: |
    # Based on research - prefer /dev/null to avoid infinite loops
    # Some systemd-journald versions can cause infinite CPU usage if linking to /dev/console
    if [ ! -e /dev/kmsg ]; then
      ln -sf /dev/null /dev/kmsg
      echo "Created /dev/kmsg -> /dev/null"
    else
      echo "/dev/kmsg already exists"
    fi
  when: 
    - is_lxc_container
    - not dev_kmsg_stat.stat.exists

- name: Create systemd tmpfile for persistent /dev/kmsg
  ansible.builtin.copy:
    dest: /etc/tmpfiles.d/kmsg.conf
    content: |
      # Kubernetes kubelet requires /dev/kmsg
      # Link to /dev/null to avoid systemd-journald infinite loops
      L /dev/kmsg - - - - /dev/null
    owner: root
    group: root
    mode: 0644
  when: is_lxc_container

- name: Create advanced /dev/kmsg service with proper dependencies
  ansible.builtin.copy:
    dest: /etc/systemd/system/create-kmsg.service
    content: |
      [Unit]
      Description=Create /dev/kmsg for LXC Kubernetes compatibility
      Documentation=https://kubernetes.io/docs/setup/production-environment/container-runtimes/
      DefaultDependencies=false
      Before=rke2-server.service rke2-agent.service kubelet.service
      ConditionPathExists=!/dev/kmsg

      [Service]
      Type=oneshot
      ExecStart=/bin/sh -c 'ln -sf /dev/null /dev/kmsg 2>/dev/null || true'
      ExecStart=/bin/sh -c 'systemd-tmpfiles --create /etc/tmpfiles.d/kmsg.conf || true'
      RemainAfterExit=yes
      StandardOutput=journal
      StandardError=journal

      [Install]
      WantedBy=multi-user.target sysinit.target
    owner: root
    group: root
    mode: 0644
  when: is_lxc_container

- name: Enable and start /dev/kmsg creation service
  ansible.builtin.systemd:
    name: create-kmsg.service
    enabled: true
    state: started
    daemon_reload: true
  when: is_lxc_container

# Ensure RKE2 configuration directory exists
- name: Create RKE2 configuration directory
  ansible.builtin.file:
    path: /etc/rancher/rke2
    state: directory
    owner: root
    group: root
    mode: '0755'
    recurse: true
  when: is_lxc_container

# REMOVED: config-lxc-override.yaml creation - no longer needed
# All LXC optimizations are now included in the main kubelet-config.yaml template
# This prevents configuration conflicts and duplicate kubelet-arg entries

- name: Check if main config exists before merging
  ansible.builtin.stat:
    path: /etc/rancher/rke2/config.yaml
  register: main_config_stat
  when: is_lxc_container

# CRITICAL FIX: Prevent kubelet from looking for config files but allow device-plugins directory
- name: Prevent kubelet config file issues in LXC containers
  ansible.builtin.shell: |
    echo "Configuring kubelet directory structure for LXC container"
    
    # NOTE: Do not stop RKE2 service here - it may not be started yet
    # Service management is handled by the main deployment tasks
    
    # Create kubelet directory structure with proper permissions
    mkdir -p /var/lib/kubelet/device-plugins
    mkdir -p /var/lib/kubelet/pods
    mkdir -p /var/lib/kubelet/plugins
    mkdir -p /var/lib/kubelet/plugins_registry
    mkdir -p /var/lib/kubelet/checkpoints
    
    # CRITICAL: Ensure NO conflicting kubelet config files exist
    rm -f /var/lib/kubelet/config.yaml
    
    # Set proper ownership and permissions
    chown -R root:root /var/lib/kubelet
    chmod -R 755 /var/lib/kubelet
    
    # Ensure device-plugins directory has proper permissions
    chmod 755 /var/lib/kubelet/device-plugins
    
    # Create a README to document the LXC configuration approach
    echo "# LXC Container Kubelet Configuration" > /var/lib/kubelet/README-LXC
    echo "# This kubelet instance is configured via kubelet-config.yaml" >> /var/lib/kubelet/README-LXC
    echo "# located at /etc/rancher/rke2/kubelet-config.yaml" >> /var/lib/kubelet/README-LXC
    echo "# DO NOT create conflicting config files in this directory" >> /var/lib/kubelet/README-LXC
    
    # Verify directory structure
    ls -la /var/lib/kubelet/
    
    echo "Kubelet directory structure configured for LXC compatibility"
  when: is_lxc_container
  register: kubelet_config_prevention
  changed_when: false

# Additional fix: Create systemd override directory for future use if needed
- name: Create kubelet config directory override
  ansible.builtin.file:
    path: /etc/systemd/system/rke2-server.service.d
    state: directory
    mode: 0755
    owner: root
    group: root
  when: 
    - is_lxc_container
    - inventory_hostname in groups[rke2_servers_group_name]

# REMOVED: Conflicting systemd override that forces --config=/dev/null
# This was causing conflicts with our kubelet-config.yaml approach

- name: Display kubelet config prevention results
  ansible.builtin.debug:
    var: kubelet_config_prevention.stdout_lines
  when: is_lxc_container

- name: Backup original config if it exists
  ansible.builtin.copy:
    src: /etc/rancher/rke2/config.yaml
    dest: /etc/rancher/rke2/config.yaml.backup
    remote_src: true
  when: 
    - is_lxc_container
    - main_config_stat.stat.exists

# REMOVED: Merging config-lxc-override.yaml to prevent kubelet configuration conflicts
# The main config.yaml template now includes all necessary LXC optimizations
# This prevents duplicate kubelet-arg entries that cause deployment failures
# Note: Removed orphaned group reference that was causing task errors

- name: Check config file existence before setting permissions
  ansible.builtin.stat:
    path: /etc/rancher/rke2/config.yaml
  register: config_file_check
  when: is_lxc_container

- name: Ensure correct permissions on final config
  ansible.builtin.file:
    path: /etc/rancher/rke2/config.yaml
    owner: root
    group: root
    mode: 0600
  when: 
    - is_lxc_container
    - config_file_check.stat.exists

- name: Verify RKE2 configuration contains LXC fixes
  ansible.builtin.shell: |
    echo "Verifying RKE2 configuration for LXC compatibility..."
    
    if [ -f /etc/rancher/rke2/config.yaml ]; then
      echo "=== CURRENT RKE2 CONFIG ==="
      cat /etc/rancher/rke2/config.yaml
      echo ""
      echo "=== VERIFICATION ==="
      
      # Check for kubelet config reference (main approach)
      if grep -q "config=/etc/rancher/rke2/kubelet-config.yaml" /etc/rancher/rke2/config.yaml; then
        echo "✅ kubelet-config.yaml reference: FOUND"
      else
        echo "❌ kubelet-config.yaml reference: MISSING"
      fi
      
      # Check if SQLite mode is enabled
      if grep -q "disable-etcd.*true" /etc/rancher/rke2/config.yaml; then
        echo "✅ SQLite mode (disable-etcd): DETECTED"
        echo "   Skipping etcd-specific checks for SQLite mode"
      else
        echo "ℹ️  etcd mode: DETECTED"
        # Only check etcd-related settings in etcd mode
        if grep -q "protect-kernel-defaults=false" /etc/rancher/rke2/config.yaml; then
          echo "✅ protect-kernel-defaults=false: FOUND"
        else
          echo "❌ protect-kernel-defaults=false: MISSING"
        fi
      fi
      
      if grep -q "fail-swap-on=false" /etc/rancher/rke2/config.yaml; then
        echo "✅ fail-swap-on=false: FOUND"  
      else
        echo "❌ fail-swap-on=false: MISSING"
      fi
    else
      echo "❌ ERROR: /etc/rancher/rke2/config.yaml not found!"
    fi
  register: config_verification
  when: is_lxc_container
  changed_when: false

- name: Display config verification results
  ansible.builtin.debug:
    var: config_verification.stdout_lines
  when: is_lxc_container

- name: Reload systemd daemon for LXC service files
  ansible.builtin.systemd:
    daemon_reload: true
  when: is_lxc_container

- name: Ensure RKE2 server service is prepared for LXC deployment
  ansible.builtin.debug:
    msg: |
      RKE2 service preparation for LXC:
      - Service start/stop will be managed by main deployment tasks
      - LXC optimizations are applied to systemd service files
      - Configuration conflicts have been prevented
  when: 
    - is_lxc_container
    - inventory_hostname in groups[rke2_servers_group_name]

# GPU passthrough and device access optimizations for LXC
- name: Configure GPU device access for LXC containers
  ansible.builtin.shell: |
    echo "GPU PASSTHROUGH CONFIGURATION FOR LXC"
    echo "======================================"
    
    # Check if NVIDIA devices are available
    if [ -d /dev/nvidia-smi ] || [ -f /usr/bin/nvidia-smi ]; then
      echo "SUCCESS: NVIDIA devices detected"
      
      # Ensure nvidia-container-runtime is available
      if command -v nvidia-container-runtime >/dev/null 2>&1; then
        echo "SUCCESS: nvidia-container-runtime available"
      else
        echo "WARNING: nvidia-container-runtime not found - may need installation"
      fi
      
      # Check for NVIDIA device nodes
      nvidia_devices=$(find /dev -name "nvidia*" 2>/dev/null | wc -l)
      echo "INFO: Found $nvidia_devices NVIDIA device nodes"
      
    else
      echo "INFO: No NVIDIA devices detected (this is normal for CPU-only deployments)"
    fi
    
    # Check for other GPU devices (AMD, Intel)
    if [ -d /dev/dri ]; then
      dri_devices=$(ls -la /dev/dri/ | grep -c "card\|render")
      echo "INFO: Found $dri_devices DRI devices in /dev/dri"
    fi
    
    # Create device access script
    cat > /usr/local/bin/setup-gpu-devices.sh << 'EOFGPU'
    #!/bin/bash
    # GPU Device Setup for LXC Kubernetes
    set -e
    
    # Ensure proper permissions on device nodes
    if [ -d /dev/nvidia0 ]; then
        chmod 666 /dev/nvidia*
        echo "SUCCESS: NVIDIA device permissions set"
    fi
    
    if [ -d /dev/dri ]; then
        chmod 666 /dev/dri/*
        echo "SUCCESS: DRI device permissions set"
    fi
    EOFGPU
    
    chmod +x /usr/local/bin/setup-gpu-devices.sh
    echo "SUCCESS: GPU device setup script created"
  register: gpu_setup_result
  when: is_lxc_container
  changed_when: false

- name: Display GPU setup results
  ansible.builtin.debug:
    var: gpu_setup_result.stdout_lines
  when: is_lxc_container

# Advanced LXC mount optimizations for Kubernetes workloads
- name: Configure advanced mount optimizations for LXC
  ansible.builtin.copy:
    dest: /usr/local/bin/lxc-mount-optimizations.sh
    content: |
      #!/bin/bash
      # Advanced LXC Mount Optimizations for Kubernetes
      set -e
      
      echo "LXC MOUNT OPTIMIZATIONS"
      echo "======================="
      
      # Ensure /proc and /sys are mounted with proper options
      if ! mount | grep -q "proc.*rw"; then
        echo "WARNING: /proc not mounted read-write - this may cause issues"
      else
        echo "SUCCESS: /proc mounted read-write"
      fi
      
      if ! mount | grep -q "sys.*rw"; then
        echo "WARNING: /sys not mounted read-write - this may cause issues"
      else
        echo "SUCCESS: /sys mounted read-write"
      fi
      
      # Ensure shared mount propagation for Kubernetes
      if ! findmnt / -o PROPAGATION | grep -q shared; then
        echo "INFO: Setting up shared mount propagation"
        mount --make-rshared /
        echo "SUCCESS: Root filesystem set to shared propagation"
      else
        echo "SUCCESS: Mount propagation already configured"
      fi
      
      # Optimize tmpfs mounts for Kubernetes
      if [ ! -d /run/k3s ]; then
        mkdir -p /run/k3s
      fi
      
      # Ensure proper permissions on Kubernetes directories
      mkdir -p /var/lib/kubelet
      mkdir -p /var/lib/rancher/rke2
      mkdir -p /var/log/pods
      
      # Set SELinux contexts if available
      if command -v selinuxenabled >/dev/null 2>&1 && selinuxenabled; then
        echo "INFO: Configuring SELinux contexts for Kubernetes"
        setsebool -P container_manage_cgroup true
        setsebool -P virt_use_nfs true
      fi
      
      echo "SUCCESS: Mount optimizations complete"
    mode: 0755
    owner: root
    group: root
  when: is_lxc_container

- name: Create systemd service for LXC mount optimizations
  ansible.builtin.copy:
    dest: /etc/systemd/system/lxc-mount-optimizations.service
    content: |
      [Unit]
      Description=LXC Mount Optimizations for Kubernetes
      Documentation=https://kubernetes.io/docs/setup/production-environment/
      DefaultDependencies=false
      Before=rke2-server.service rke2-agent.service containerd.service
      After=local-fs.target

      [Service]
      Type=oneshot
      ExecStart=/usr/local/bin/lxc-mount-optimizations.sh
      RemainAfterExit=yes
      StandardOutput=journal
      StandardError=journal

      [Install]
      WantedBy=multi-user.target
    owner: root
    group: root
    mode: 0644
  when: is_lxc_container

- name: Enable LXC mount optimizations service
  ansible.builtin.systemd:
    name: lxc-mount-optimizations.service
    enabled: true
    state: started
    daemon_reload: true
  when: is_lxc_container

# Production-grade health check script with comprehensive validation
- name: Create comprehensive LXC health check script
  ansible.builtin.copy:
    dest: /usr/local/bin/rke2-lxc-health-check.sh
    content: |
      #!/bin/bash
      # Comprehensive RKE2 LXC Health Check Script
      # Based on production Kubernetes LXC best practices
      set -e
      
      echo "COMPREHENSIVE RKE2 LXC HEALTH CHECK"
      echo "==================================="
      
      # Color codes for output
      RED='\033[0;31m'
      GREEN='\033[0;32m'
      YELLOW='\033[1;33m'
      BLUE='\033[0;34m'
      NC='\033[0m' # No Color
      
      # Check 1: Container Environment
      echo -e "${BLUE}Container Environment:${NC}"
      if grep -qa container=lxc /proc/1/environ; then
        echo -e "  ${GREEN}SUCCESS: Running in LXC container${NC}"
      else
        echo -e "  ${YELLOW}WARNING: Not detected as LXC container${NC}"
      fi
      
      # Check 2: Required kernel modules
      echo -e "${BLUE}Kernel Modules:${NC}"
      for module in br_netfilter overlay ip_tables ip6_tables nf_nat; do
        if grep -q "^$module " /proc/modules 2>/dev/null; then
          echo -e "  ${GREEN}SUCCESS: $module: loaded${NC}"
        else
          echo -e "  ${YELLOW}WARNING: $module: not loaded${NC}"
        fi
      done
      
      # Check 3: Critical device nodes
      echo -e "${BLUE}Device Nodes:${NC}"
      if [ -e /dev/kmsg ]; then
        echo -e "  ${GREEN}SUCCESS: /dev/kmsg: exists${NC}"
      else
        echo -e "  ${RED}ERROR: /dev/kmsg: missing${NC}"
      fi
      
      # Check 4: Sysctl configuration
      echo -e "${BLUE}Sysctl Configuration:${NC}"
      if [ -f /proc/sys/net/bridge/bridge-nf-call-iptables ]; then
        bridge_iptables=$(cat /proc/sys/net/bridge/bridge-nf-call-iptables)
        if [ "$bridge_iptables" = "1" ]; then
          echo -e "  ${GREEN}SUCCESS: bridge-nf-call-iptables: enabled${NC}"
        else
          echo -e "  ${RED}ERROR: bridge-nf-call-iptables: disabled${NC}"
        fi
      else
        echo -e "  ${YELLOW}WARNING: bridge-nf-call-iptables: not accessible${NC}"
      fi
      
      # Check 5: RKE2 service status
      echo -e "${BLUE}RKE2 Service Status:${NC}"
      if systemctl is-active rke2-server.service >/dev/null 2>&1; then
        echo -e "  ${GREEN}SUCCESS: RKE2 server service: active${NC}"
        
        # Check RKE2 process
        if pgrep -f "rke2 server" >/dev/null; then
          echo -e "  ${GREEN}SUCCESS: RKE2 server process: running${NC}"
        else
          echo -e "  ${YELLOW}WARNING: RKE2 server process: not found${NC}"
        fi
      elif systemctl is_active rke2-agent.service >/dev/null 2>&1; then
        echo -e "  ${GREEN}SUCCESS: RKE2 agent service: active${NC}"
      else
        echo -e "  ${RED}ERROR: RKE2 service: not active${NC}"
        systemctl status rke2-server.service --no-pager -l || systemctl status rke2-agent.service --no-pager -l || true
      fi
      
      # Check 6: Kubernetes API accessibility
      echo -e "${BLUE}Kubernetes API:${NC}"
      if [ -f /etc/rancher/rke2/rke2.yaml ]; then
        export KUBECONFIG=/etc/rancher/rke2/rke2.yaml
        PATH="/var/lib/rancher/rke2/bin:$PATH"
        
        if timeout 30 kubectl get nodes >/dev/null 2>&1; then
          echo -e "  ${GREEN}SUCCESS: Kubernetes API: responding${NC}"
          echo -e "${BLUE}Cluster Status:${NC}"
          kubectl get nodes -o wide | sed 's/^/    /'
          
          # Check pod status
          echo -e "${BLUE}System Pods:${NC}"
          kubectl get pods -n kube-system --no-headers | awk '{print "    " $1 ": " $3}' || true
          
        else
          echo -e "  ${YELLOW}INFO: Kubernetes API: not ready yet (normal during startup)${NC}"
        fi
      else
        echo -e "  ${YELLOW}WARNING: RKE2 kubeconfig not found${NC}"
      fi
      
      # Check 7: Container runtime
      echo -e "${BLUE}Container Runtime:${NC}"
      if [ -S /run/k3s/containerd/containerd.sock ]; then
        echo -e "  ${GREEN}SUCCESS: Containerd socket: available${NC}"
        
        # Check containerd service
        if systemctl is-active containerd >/dev/null 2>&1; then
          echo -e "  ${GREEN}SUCCESS: Containerd service: active${NC}"
        fi
      else
        echo -e "  ${RED}ERROR: Containerd socket: not found${NC}"
      fi
      
      # Check 8: Resource usage
      echo -e "${BLUE}Resource Usage:${NC}"
      memory_total=$(free -h | awk '/^Mem:/ {print $2}')
      memory_used=$(free -h | awk '/^Mem:/ {print $3}')
      disk_usage=$(df -h / | awk 'NR==2 {print $5}')
      
      echo -e "  Memory: $memory_used / $memory_total"
      echo -e "  Disk: $disk_usage used"
      
      # Check 9: GPU devices (if applicable)
      echo -e "${BLUE}GPU Devices:${NC}"
      if [ -d /dev/nvidia0 ] || command -v nvidia-smi >/dev/null 2>&1; then
        echo -e "  ${GREEN}SUCCESS: NVIDIA devices detected${NC}"
        if command -v nvidia-smi >/dev/null 2>&1; then
          nvidia-smi --query-gpu=name,memory.total --format=csv,noheader | sed 's/^/    /' || true
        fi
      elif [ -d /dev/dri ]; then
        dri_count=$(ls /dev/dri/ | grep -c "card" || echo "0")
        echo -e "  ${GREEN}SUCCESS: DRI devices: $dri_count found${NC}"
      else
        echo -e "  INFO: No GPU devices detected (CPU-only deployment)"
      fi
      
      # Final assessment
      echo ""
      echo -e "${BLUE}HEALTH CHECK SUMMARY:${NC}"
      if systemctl is-active rke2-server.service >/dev/null 2>&1 || systemctl is-active rke2-agent.service >/dev/null 2>&1; then
        echo -e "${GREEN}SUCCESS: RKE2 deployment appears healthy${NC}"
        echo -e "   Monitor progress with: ${YELLOW}journalctl -u rke2-server.service -f${NC}"
      else
        echo -e "${RED}ERROR: RKE2 deployment needs attention${NC}"
        echo -e "   Check logs with: ${YELLOW}journalctl -u rke2-server.service -n 50${NC}"
      fi
      
      echo -e "${BLUE}Useful commands:${NC}"
      echo -e "   kubectl get nodes: ${YELLOW}kubectl get nodes -o wide${NC}"
      echo -e "   Check pods: ${YELLOW}kubectl get pods -A${NC}"
      echo -e "   RKE2 logs: ${YELLOW}journalctl -u rke2-server.service -f${NC}"
      echo ""
      echo -e "${GREEN}SUCCESS: LXC RKE2 health check complete${NC}"
    mode: 0755
    owner: root
    group: root
  when: is_lxc_container

# Enhanced deployment summary with comprehensive information
- name: Display comprehensive LXC deployment summary
  ansible.builtin.debug:
    msg: |
      
      COMPREHENSIVE LXC-OPTIMIZED RKE2 CONFIGURATION APPLIED
      ======================================================
      
      ARCHITECTURE OPTIMIZATIONS:
      - Container Type: {{ container_type.stdout }}
      - Privileged Mode: Required for Kubernetes components
      - Network Mode: Bridged with full networking capabilities
      - GPU Passthrough: Optimized for low-overhead GPU access
      
      APPLIED CONFIGURATIONS:
      - Enhanced RKE2 Config: Integrated into main playbook configuration
      - Kubelet Settings: Comprehensive config file with LXC optimizations
      - Network Stack: Bridge netfilter, IP forwarding, conntrack optimization
      - Sysctl Tuning: Container-optimized kernel parameters
      - Device Access: /dev/kmsg created for kubelet compatibility
      
      PERFORMANCE OPTIMIZATIONS:
      - Resource Limits: System and Kube reserved resources configured
      - Connection Limits: Increased netdev backlog and connection tracking
      - Memory Management: Optimized vm.max_map_count and inotify limits
      - Process Limits: Enhanced pid_max and threads-max for dense workloads
      
      SECURITY ENHANCEMENTS:
      - Authentication: Token webhook and proper CA configuration
      - Authorization: Webhook-based authorization mode
      - Admission Control: NodeRestriction, ResourceQuota, LimitRanger
      - Anonymous Access: Disabled for security
      
      GPU PASSTHROUGH BENEFITS:
      - Low Overhead: LXC containers vs KVM VMs for GPU workloads
      - Device Plugins: Enabled for GPU device management
      - Performance: Near-native GPU performance with minimal virtualization overhead
      
      DEPLOYMENT NOTES:
      - Startup Time: LXC containers may take 2-3 minutes for full initialization
      - Health Check: Use /usr/local/bin/rke2-lxc-health-check.sh for validation
      - Monitoring: Check 'kubectl get nodes' once API server is ready
      - Troubleshooting: Monitor with 'journalctl -u rke2-server.service -f'
      
      ARCHITECTURE SOURCES:
      - Based on production practices from kubernetes-lxd, VirtualizationHowto
      - Optimized for Proxmox LXC with GPU passthrough requirements
      - Production-grade configuration with comprehensive error handling
      
      Ready for RKE2 deployment!
  when: is_lxc_container
