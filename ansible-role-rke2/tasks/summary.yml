---

- name: Check and remove cloud provider uninitialized taint (prevents pod scheduling)
  ansible.builtin.shell: |
    echo "=== Checking for cloud provider uninitialized taints ==="
    {{ rke2_data_path }}/bin/kubectl --kubeconfig /etc/rancher/rke2/rke2.yaml get nodes -o custom-columns="NODE:.metadata.name,TAINTS:.spec.taints[*].key" | grep -E "cloudprovider|uninitialized" || echo "No cloud provider taints found"
    echo ""
    echo "=== Removing cloud provider uninitialized taint from all nodes ==="
    {{ rke2_data_path }}/bin/kubectl --kubeconfig /etc/rancher/rke2/rke2.yaml taint nodes --all node.cloudprovider.kubernetes.io/uninitialized- || echo "Taint not present or already removed"
    echo ""
    echo "=== Verifying taints after removal ==="
    {{ rke2_data_path }}/bin/kubectl --kubeconfig /etc/rancher/rke2/rke2.yaml describe nodes | grep -A 2 "Taints:" || echo "No taints found"
  args:
    executable: /bin/bash
  when: inventory_hostname == groups[rke2_servers_group_name].0
  register: taint_removal_result

- name: Display taint removal results
  ansible.builtin.debug:
    var: taint_removal_result.stdout_lines
  when: inventory_hostname == groups[rke2_servers_group_name].0

- name: Wait for critical system pods to be ready after taint removal
  ansible.builtin.shell: |
    echo "Waiting for system pods to schedule after taint removal..."
    {{ rke2_data_path }}/bin/kubectl --kubeconfig /etc/rancher/rke2/rke2.yaml wait --for=condition=ready pod -l k8s-app=kube-dns -n kube-system --timeout=300s || echo "CoreDNS wait timed out"
    {{ rke2_data_path }}/bin/kubectl --kubeconfig /etc/rancher/rke2/rke2.yaml wait --for=condition=ready pod -l app.kubernetes.io/name=metrics-server -n kube-system --timeout=300s || echo "Metrics server wait timed out"
  args:
    executable: /bin/bash
  when: inventory_hostname == groups[rke2_servers_group_name].0
  register: system_pods_wait

- name: Download RKE2 kubeconfig to localhost
  ansible.builtin.fetch:
    src: /etc/rancher/rke2/rke2.yaml
    dest: "{{ rke2_download_kubeconf_path }}/{{ rke2_download_kubeconf_file_name }}"
    flat: yes
  when:
  - rke2_download_kubeconf | bool
  - inventory_hostname == groups[rke2_servers_group_name].0

- name: Replace loopback IP by master server IP
  ansible.builtin.replace:
    path: "{{ rke2_download_kubeconf_path }}/{{ rke2_download_kubeconf_file_name }}"
    mode: '0600'
    regexp: '127.0.0.1'
    replace: "{{ rke2_api_ip | default(hostvars[groups[rke2_servers_group_name].0].ansible_host) }}"
  delegate_to: localhost
  become: false
  when:
  - not ansible_check_mode
  - rke2_download_kubeconf | bool
  - inventory_hostname == groups[rke2_servers_group_name].0

- name: Summary
  when: inventory_hostname == groups[rke2_servers_group_name].0
  block:
    - name: Prepare summary
      ansible.builtin.shell: |
        set -e
        {{ rke2_data_path }}/bin/kubectl --kubeconfig /etc/rancher/rke2/rke2.yaml get nodes -o wide --show-labels
      args:
        executable: /bin/bash
      changed_when: false
      retries: 5
      register: nodes_summary

    - name: K8s nodes state
      ansible.builtin.debug:
        var: nodes_summary.stdout_lines

    # Label GPU nodes for proper scheduling after cluster is ready
    - name: Label GPU nodes for Kubernetes scheduling
      ansible.builtin.shell: |
        echo "Labeling GPU nodes for proper scheduling..."
        
        {% for host in groups.get('gpu_nodes', []) %}
        # Label {{ host }} as GPU worker
        {{ rke2_data_path }}/bin/kubectl --kubeconfig /etc/rancher/rke2/rke2.yaml label nodes {{ host }} node-type=gpu-worker --overwrite
        {{ rke2_data_path }}/bin/kubectl --kubeconfig /etc/rancher/rke2/rke2.yaml label nodes {{ host }} nvidia.com/gpu.present=true --overwrite
        echo "SUCCESS: GPU node {{ host }} labeled for GPU workloads"
        
        {% endfor %}
        {% for host in groups['all'] %}
        {% if hostvars[host].get('is_gpu_node', false) %}
        # Label {{ host }} as GPU worker (from is_gpu_node variable)
        {{ rke2_data_path }}/bin/kubectl --kubeconfig /etc/rancher/rke2/rke2.yaml label nodes {{ host }} node-type=gpu-worker --overwrite
        {{ rke2_data_path }}/bin/kubectl --kubeconfig /etc/rancher/rke2/rke2.yaml label nodes {{ host }} nvidia.com/gpu.present=true --overwrite
        echo "SUCCESS: GPU node {{ host }} labeled for GPU workloads"
        
        {% endif %}
        {% endfor %}
        echo "GPU node labeling completed"
      args:
        executable: /bin/bash
      register: gpu_labeling_result
      changed_when: "'SUCCESS' in gpu_labeling_result.stdout"
      when: (groups.get('gpu_nodes', []) | length > 0) or (groups['all'] | map('extract', hostvars) | selectattr('is_gpu_node', 'defined') | selectattr('is_gpu_node') | list | length > 0)

    - name: Display GPU node labeling results
      ansible.builtin.debug:
        var: gpu_labeling_result.stdout_lines
      when: gpu_labeling_result is defined
