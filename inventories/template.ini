# =============================================================================
# RKE2 CLUSTER INVENTORY TEMPLATE
# =============================================================================
#
# INSTRUCTIONS:
# 1. Copy this file to 'hosts.ini' (or any name you prefer)
# 2. Replace ALL placeholders marked with <...> with your actual values
# 3. Update the IP addresses in the [rke2_servers] and [rke2_agents] sections
# 4. Ensure the rke2_token is changed to a secure random string
# 5. Save the file and run: ./deploy.sh hosts.ini
#
# SECURITY WARNING: 
# - Change the rke2_token to a secure random string (minimum 32 characters)
# - Use the same password for cluster_admin_user across ALL containers
#
# =============================================================================

[rke2_cluster:children]
rke2_servers
rke2_agents

[rke2_cluster:vars]
# =============================================================================
# CLUSTER CONFIGURATION - UPDATE THESE VALUES
# =============================================================================

# REQUIRED: Change to a secure random token (32+ characters recommended)
# Example: 1nIV9EumO0LneWwel6SbpVOulDljle1F
rke2_token=CHANGE-THIS-TO-SECURE-RANDOM-TOKEN

# REQUIRED: IP address of your control plane node
rke2_api_ip=<CONTROL-PLANE-IP>

# RKE2 version - updated to latest stable release with bug fixes
rke2_version=v1.33.3+rke2r1

# =============================================================================
# NETWORK CONFIGURATION - Adjust if needed for your environment
# =============================================================================
cluster_cidr=10.42.0.0/16
service_cidr=10.43.0.0/16
cluster_dns=10.43.0.10

# =============================================================================
# DEPLOYMENT OPTIONS - Configure as needed
# =============================================================================

# Administrative user for Kubernetes access (created manually before deployment)
# This user will have kubectl, helm, and k9s access configured
cluster_admin_user=adm4n

# Output kubeconfig filename (will be saved in kubeconfs/ directory)
rke2_download_kubeconf_file_name=<YOUR-CLUSTER-NAME>.yaml

# Enable local-path-provisioner for persistent storage
use_local_path_provisioner=true
local_path_provisioner_path=/mnt/data

# SQLite mode for LXC deployments (RECOMMENDED for LXC containers)
# Set to true for single control plane + multiple agents
# Set to false for traditional etcd (multi-control plane HA)
rke2_use_sqlite=true

# Rancher UI - DISABLED (using k9s terminal UI for diagnostics)
install_rancher=false

# Compatibility variable for ansible-role-rke2
k8s_cluster=rke2_cluster

# =============================================================================
# NODE DEFINITIONS - UPDATE WITH YOUR ACTUAL IP ADDRESSES
# =============================================================================

[rke2_servers]
# CONTROL PLANE NODES
# Format: <IP_ADDRESS> ansible_user=<USERNAME> rke2_type=server
# 
# Example for the architecture in README.md:
# 10.14.100.1 ansible_user=adm4n rke2_type=server
#
<CONTROL-PLANE-IP> ansible_user=<USERNAME> rke2_type=server

[rke2_agents]
# WORKER NODES (including GPU nodes)
# Format: <IP_ADDRESS> ansible_user=<USERNAME> rke2_type=agent
#
# Example for the architecture in README.md:
# 10.14.100.2 ansible_user=adm4n rke2_type=agent
# 10.14.100.3 ansible_user=adm4n rke2_type=agent
#
<GPU-WORKER-1-IP> ansible_user=<USERNAME> rke2_type=agent
<GPU-WORKER-2-IP> ansible_user=<USERNAME> rke2_type=agent

# =============================================================================
# ANSIBLE CONNECTION CONFIGURATION - DO NOT CHANGE
# =============================================================================
[all:vars]
# SSH and privilege escalation configuration for passwordless operation
ansible_ssh_private_key_file=~/.ssh/id_ed25519
ansible_ssh_common_args='-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null'
ansible_become=yes
ansible_become_method=sudo
ansible_become_user=root
ansible_become_pass=